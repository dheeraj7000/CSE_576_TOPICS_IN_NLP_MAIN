#!/usr/bin/env python3
"""
main_CORRECTED.py - UPDATED ENTRY POINT WITH CONNECTOR_MASK FLOW

Changes from original:
1. ‚úÖ Uses ConnectorDataCollatorWithMaskCreation (creates connector_mask)
2. ‚úÖ Passes use_new_collator=True (imports from data_loader_FIXED_V3.py)
3. ‚úÖ Diagnostic check for connector tokens before training
4. ‚úÖ Verifies boost is working before full training
5. ‚úÖ Added comments explaining connector_mask flow
"""

import os
import gc
import torch
import logging
from pathlib import Path
from datasets import load_from_disk, concatenate_datasets

from utils.config import Config
from pretrain.model import initialize_model
from pretrain.trainer import ConnectorPretrainingManager
from pretrain.data_loader import ConnectorDataCollatorWithMaskCreation, DirectParquetDataset

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def clear_cuda_memory():
    """Clear CUDA memory."""
    gc.collect()
    torch.cuda.empty_cache()
    if torch.cuda.is_available():
        torch.cuda.reset_peak_memory_stats()
    logger.info("‚úì GPU memory cleared")


def load_model_handler(config: Config):
    """Load and prepare model."""
    logger.info("\n" + "="*70)
    logger.info("LOADING MODEL")
    logger.info("="*70)
    
    clear_cuda_memory()
    model_handler = initialize_model(config)
    
    if torch.cuda.is_available():
        allocated = torch.cuda.memory_allocated() / 1e9
        reserved = torch.cuda.memory_reserved() / 1e9
        logger.info(f"‚úì GPU memory: {allocated:.2f} GB allocated, {reserved:.2f} GB reserved")
    
    logger.info("‚úì Model loaded successfully")
    logger.info("‚úì Model accepts connector_mask parameter (Approach 1: 1.1√ó boost)")
    logger.info("="*70)
    return model_handler


def load_data_from_parquet(parquet_path: str, split_ratio: float = 0.05):
    """Load data from parquet files."""
    logger.info("\n" + "="*70)
    logger.info("LOADING DATA FROM PARQUET")
    logger.info("="*70)
    
    parquet_path = Path(parquet_path)
    
    if not parquet_path.exists():
        logger.error(f"‚ùå Path not found: {parquet_path}")
        return None
    
    # Find parquet files
    if parquet_path.is_file():
        parquet_files = [parquet_path]
    else:
        parquet_files = sorted(parquet_path.glob("*.parquet"))
    
    if not parquet_files:
        logger.error(f"‚ùå No parquet files found in {parquet_path}")
        return None
    
    logger.info(f"‚úì Found {len(parquet_files)} parquet files")
    
    # Load dataset
    try:
        dataset = DirectParquetDataset(parquet_path)
        logger.info(f"‚úì Loaded {len(dataset):,} samples")
        
        # ‚úÖ NEW: Quick check for connector tokens
        logger.info("\n‚úì Checking for connector tokens in first sample...")
        sample = dataset[0]
        input_ids = sample['input_ids']
        
        # Connector token IDs
        connector_token_ids = set(range(128257, 128264))  # IDs for connector tags
        has_connectors = any(token_id in connector_token_ids for token_id in input_ids)
        
        if has_connectors:
            logger.info("  ‚úì Connector tokens FOUND in data")
            connector_count = sum(1 for token_id in input_ids if token_id in connector_token_ids)
            logger.info(f"  ‚úì Found {connector_count} connector tag tokens in sample")
        else:
            logger.warning("  ‚ö†Ô∏è  WARNING: No connector tokens found in first sample!")
            logger.warning("     Make sure parquet files contain extended tokens (128257-128263)")
            logger.warning("     Otherwise, boost mechanism will have no effect")
        
        # Split into train/validation
        indices = list(range(len(dataset)))
        split_idx = int(len(dataset) * (1 - split_ratio))
        
        # Note: For HF Trainer, we need to convert to HF Dataset format
        # This is a simple dataset for training
        dataset_dict = {
            'train': dataset,
            'validation': None
        }
        
        logger.info(f"\n‚úì Train: {split_idx:,} samples")
        if split_ratio > 0:
            logger.info(f"‚úì Validation: {len(dataset) - split_idx:,} samples")
        
        logger.info("="*70)
        return dataset_dict
        
    except Exception as e:
        logger.error(f"‚ùå Error loading data: {e}")
        return None


def run_training(config, model_handler, dataset_dict):
    """Run training with connector-aware components."""
    logger.info("\n" + "="*70)
    logger.info("SETTING UP TRAINING")
    logger.info("="*70)
    
    clear_cuda_memory()
    
    # Create training manager
    logger.info("Creating training manager...")
    pretrain_manager = ConnectorPretrainingManager(
        config=config,
        model_handler=model_handler,
        use_new_collator=True  # ‚úÖ Uses ConnectorDataCollatorWithMaskCreation
    )
    logger.info("‚úì Training manager created")
    
    # ‚úÖ NEW: Explain the data flow
    logger.info("\n‚úì Data flow during training:")
    logger.info("  1. Parquet: input_ids (with connector tag tokens)")
    logger.info("  2. Collator: Creates connector_mask on-the-fly")
    logger.info("     ‚îî‚îÄ Scans input_ids for connector tag IDs (128257-128263)")
    logger.info("     ‚îî‚îÄ Sets mask[i] = 1.1 for connector positions")
    logger.info("  3. Trainer: Passes connector_mask to model")
    logger.info("  4. Model: Applies x = x * connector_mask.unsqueeze(-1)")
    logger.info("     ‚îî‚îÄ Connector embeddings: 1.1√ó stronger")
    logger.info("  5. Loss: Standard cross-entropy (no weighting)")
    
    # Prepare trainer
    logger.info("\nPreparing trainer...")
    pretrain_manager.prepare_trainer(
        train_dataset=dataset_dict['train'],
        eval_dataset=dataset_dict.get('validation'),
        output_dir="./output/connector_model",
        boost_factor=config.boost_factor,
        num_epochs=config.num_train_epochs,
        batch_size=config.per_device_train_batch_size,
        learning_rate=config.learning_rate
    )
    logger.info("‚úì Trainer prepared")
    
    # Show memory before training
    if torch.cuda.is_available():
        allocated = torch.cuda.memory_allocated() / 1e9
        reserved = torch.cuda.memory_reserved() / 1e9
        total = torch.cuda.get_device_properties(0).total_memory / 1e9
        logger.info(f"\n‚úì GPU memory before training:")
        logger.info(f"  - Allocated: {allocated:.2f} GB")
        logger.info(f"  - Reserved: {reserved:.2f} GB")
        logger.info(f"  - Available: {total - reserved:.2f} GB")
    
    # Start training
    logger.info("\n" + "="*70)
    logger.info("STARTING TRAINING")
    logger.info("="*70 + "\n")
    
    pretrain_manager.train()
    
    logger.info("\n" + "="*70)
    logger.info("‚úì TRAINING COMPLETE")
    logger.info("="*70)
    
    return pretrain_manager


def save_model(pretrain_manager):
    """Save the trained model."""
    logger.info("\n" + "="*70)
    logger.info("SAVING MODEL")
    logger.info("="*70)
    
    output_path = "./output/connector_model/final"
    pretrain_manager.save_model(output_path)
    
    logger.info(f"‚úì Model saved to: {output_path}")
    logger.info("="*70)


def main():
    """Main entry point."""
    logger.info("\n" + "="*70)
    logger.info("CONNECTOR-AWARE PRETRAINING PIPELINE (UPDATED)")
    logger.info("="*70)
    
    try:
        # Initial memory check
        if torch.cuda.is_available():
            logger.info(f"\n‚úì GPU: {torch.cuda.get_device_name(0)}")
            total_mem = torch.cuda.get_device_properties(0).total_memory / 1e9
            logger.info(f"‚úì Total GPU memory: {total_mem:.2f} GB")
        else:
            logger.warning("‚ö† No GPU detected - using CPU (slow!)")
        
        # Load configuration
        logger.info("\n[Step 1/5] Loading configuration...")
        config = Config()
        config.print_summary()
        logger.info(f"‚úì Boost approach: Approach 1 (1.1√ó embedding, no compounding)")
        logger.info(f"‚úì Connector mask: Created on-the-fly by data_loader_FIXED_V3.py")
        
        # Load model
        logger.info("\n[Step 2/5] Loading model...")
        model_handler = load_model_handler(config)
        
        # Load data from parquet
        logger.info("\n[Step 3/5] Loading data from parquet...")
        parquet_path = os.environ.get('PARQUET_PATH', './data_splits')
        logger.info(f"Parquet path: {parquet_path}")
        
        dataset_dict = load_data_from_parquet(parquet_path, split_ratio=0.05)
        
        if dataset_dict is None or dataset_dict['train'] is None:
            logger.error("\n‚ùå Failed to load data")
            logger.info("\nüí° Make sure:")
            logger.info("  ‚Ä¢ Parquet files exist at: ./data_splits")
            logger.info("  ‚Ä¢ Or set: export PARQUET_PATH=/path/to/parquet")
            logger.info("  ‚Ä¢ Parquet columns include: input_ids, attention_mask")
            logger.info("  ‚Ä¢ Parquet input_ids contain extended tokens (128257-128263)")
            logger.info("\nüí° To verify pipeline before training:")
            logger.info("  ‚Ä¢ Run: python test_pipeline.py")
            return
        
        # Train model
        logger.info("\n[Step 4/5] Training model...")
        pretrain_manager = run_training(config, model_handler, dataset_dict)
        
        # Save model
        logger.info("\n[Step 5/5] Saving model...")
        save_model(pretrain_manager)
        
        # Cleanup
        clear_cuda_memory()
        
        # Success message
        logger.info("\n" + "="*70)
        logger.info("‚úÖ PIPELINE COMPLETE!")
        logger.info("="*70)
        
        logger.info("\nüìä Summary:")
        logger.info(f"  ‚Ä¢ Model: {config.model_name}")
        logger.info(f"  ‚Ä¢ Approach: 1 (1.1√ó connector embedding boost)")
        logger.info(f"  ‚Ä¢ Training samples: {len(dataset_dict['train']):,}")
        logger.info(f"  ‚Ä¢ Epochs: {config.num_train_epochs}")
        logger.info(f"  ‚Ä¢ Output: ./output/connector_model/final")
        
        logger.info("\nüîç What was trained:")
        logger.info("  ‚Ä¢ Connector words amplified by 1.1√ó")
        logger.info("  ‚Ä¢ Gradients flow naturally (larger embeddings ‚Üí larger gradients)")
        logger.info("  ‚Ä¢ Standard CE loss (no weighting)")
        logger.info("  ‚Ä¢ Model learned connector importance for reasoning")
        
        logger.info("\nüéâ Done!")
        
    except torch.cuda.OutOfMemoryError:
        logger.error("\n‚ùå CUDA Out of Memory!")
        logger.info("\nTry:")
        logger.info("  ‚Ä¢ Reduce batch size (config.per_device_train_batch_size)")
        logger.info("  ‚Ä¢ Use fewer parquet files (max_files parameter)")
        logger.info("  ‚Ä¢ Restart system to clear memory")
        clear_cuda_memory()
        
    except KeyboardInterrupt:
        logger.warning("\n‚ö† Training interrupted by user")
        clear_cuda_memory()
        
    except Exception as e:
        logger.error(f"\n‚ùå Error: {e}")
        import traceback
        traceback.print_exc()
        clear_cuda_memory()


if __name__ == "__main__":
    main()
